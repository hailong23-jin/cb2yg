{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比赛介绍\n",
    "\n",
    "比赛地址： [https://aistudio.baidu.com/aistudio/competition/detail/59](https://aistudio.baidu.com/aistudio/competition/detail/59)\n",
    "\n",
    "飞桨(PaddlePaddle)以百度多年的深度学习技术研究和业务应用为基础，是中国首个开源开放、技术领先、功能完备的产业级深度学习平台。更多飞桨资讯，点击此处查看。\n",
    "\n",
    "飞桨常规赛由百度飞桨于2019年发起，面向全球AI开发者，赛题范围广，涵盖领域多。常规赛旨在通过长期发布的经典比赛项目，为开发者提供学习锻炼机会。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 赛题介绍\n",
    "\n",
    "本次赛题数据集由学术网络图构成，该图会给出每个节点的特征，以及节点与节点间关系（训练集节点的标注结果已给出）。\n",
    "\n",
    "数据：\n",
    "\n",
    "输入数据是一整张图，该图包含1647958条有向边，130644个节点。\n",
    "\n",
    "提供的数据文件说明：\n",
    "\n",
    "| 数据集 | 简介 |\n",
    "| -------- | -------- | \n",
    "| edges.csv    | 边数据：用于标记论文间引用关系    | \n",
    "|feat.npy|节点数据：每个节点含100维特征|\n",
    "|train.csv|训练集数据|\n",
    "|test.csv|测试集数据|\n",
    "\n",
    "- edges.csv，用于标记论文引用关系，为无向图，且由两列组成，没有表头。\n",
    "\n",
    "- feat.npy， Numpy格式存储的节点特征矩阵，Shape为(130644, 100)，可以用numpy.load(“feat.npy”)\n",
    "\n",
    "- train.csv，包含两个字段，nid 和 label。\n",
    "\n",
    "- test.csv，只包含 nid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提交结果介绍\n",
    "\n",
    "提交内容与格式\n",
    "最终提交的submission.csv 格式如下：\n",
    "\n",
    "|字段\t| 说明 |\n",
    "| --- | --- |\n",
    "|nid  | 测试集节点在图上的id | \n",
    "|label | 测试集的节点类别|\n",
    "\n",
    "提交样例\n",
    "\n",
    "|nid | label |\n",
    "| -- | --- |\n",
    "|2  | 34 |\n",
    "|3\t| 1 |\n",
    "|4 | 5 |\n",
    "|… | … |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目杂谈\n",
    "\n",
    "环境： AI studio; **PaddlePaddle 2.1.0**;  **PGL 2.1.5**\n",
    "\n",
    "在七月份的这次比赛中，我们仅使用了单模型，没有进行模型融合，取得的分数为0.74777，获得第七名。 比较遗憾的是，模型文件被覆盖掉了。因此无法复现出原来的结果。但是我们在八月初跑出了0.74938的分数，我们将提供跑出这个结果的预训练模型\n",
    "\n",
    "项目贡献：我们的项目是第一个使用paddle2.1.0去打这个比赛的，因此我们的整个项目都是基于动态图模型，相较于paddle1.8更容易理解和修改。\n",
    "\n",
    "不足之处：由于时间关系，我们仅利用了PGL提供的一些基本图卷积算法，例如GCN，GAT，APPNP，GCNII等，没有使用更复杂的模型，比如榜首使用UniMP算法，因为没有找到现成的动态图实现，加上时间不够，也没有机会去复现这个算法，不然结果应该会更好。但是我们应该会在八月份实现一个UniMP算法的动态图版本，可以期待一下。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目介绍\n",
    "\n",
    "我们将整个项目目录结构如下:\n",
    "\n",
    "```\n",
    ".\n",
    "├── config.py       // 模型的基本配置参数\n",
    "├── model          // 保存训练好的模型\n",
    "├── network         // 使用的图神经网络算法\n",
    "│   ├── appnp.py\n",
    "│   ├── gat.py\n",
    "│   ├── gcnii.py\n",
    "│   ├── gcn.py\n",
    "│   ├── __init__.py\n",
    "│   └── transformer.py\n",
    "├── result           // 每个模型跑出的结果文件\n",
    "│   ├── APPNP.csv\n",
    "│   ├── GAT.csv\n",
    "│   ├── gat-lstm.csv\n",
    "│   ├── gcn.csv\n",
    "│   ├── GCN.csv\n",
    "│   ├── gcn-lstm.csv\n",
    "│   ├── ResGAT.csv\n",
    "│   └── sage.csv\n",
    "├── submission.csv   // 提交的结果文件\n",
    "├── train.py         // 训练文件\n",
    "└── util                  // 数据集加载以及准确率计算和模型创建函数\n",
    "    ├── __init__.py\n",
    "    ├── load_dataset.py\n",
    "    └── tools.py\n",
    "```\n",
    "\n",
    "整个项目已经完全结构化，如果需要定义自己的模型，可以将模型加入到network文件夹下，然后在 ./util/tools.py 中定义模型的初始化。 最后在train.py 中调用config, model = get_config_model('model_name') 即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install pgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果复现：直接运行下面的cell即可，模型会在当前目录下生成submission.csv文件\n",
    "\n",
    "如果要重新训练，需要将main函数中的第一个False该为Ture。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model:  ResGAT\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/aistudio/data/data101014/feat.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fc104c3b9da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# 训练完成之后立即对结果进行预测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-fc104c3b9da0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(is_train, is_predict)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# 获取训练、测试数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/proj/util/load_dataset.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# 读取节点特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mnode_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;31m# 获取节点数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/aistudio/data/data101014/feat.npy'"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F \n",
    "\n",
    "from util import *\n",
    "from network import *\n",
    "from config import Config\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# 模型训练\n",
    "def train(node_index, node_label, model, graph, criterion, optim):\n",
    "    model.train()\n",
    "    pred = model(graph, graph.node_feat[\"feat\"])\n",
    "    pred = paddle.gather(pred, node_index)\n",
    "    loss = criterion(pred, node_label)\n",
    "    loss.backward()\n",
    "\n",
    "    pred = paddle.argmax(F.softmax(pred, axis=1), axis=1).numpy()\n",
    "    node_label = node_label.flatten().numpy()\n",
    "    acc = calc_accuracy(pred, node_label)\n",
    "    optim.step()\n",
    "    optim.clear_grad()\n",
    "\n",
    "    return loss.numpy()[0], acc\n",
    "\n",
    "\n",
    "# 模型评估\n",
    "def evaluate(node_index, node_label, model, graph, criterion):\n",
    "    model.eval()\n",
    "    pred = model(graph, graph.node_feat[\"feat\"])\n",
    "    pred = paddle.gather(pred, node_index)\n",
    "    loss = criterion(pred, node_label)\n",
    "    \n",
    "    pred = paddle.argmax(F.softmax(pred, axis=1), axis=1).numpy()\n",
    "    node_label = node_label.flatten().numpy()\n",
    "    acc = calc_accuracy(pred, node_label)\n",
    "\n",
    "    return loss.numpy()[0], acc\n",
    "\n",
    "\n",
    "# 模型预测\n",
    "def predict(model, config, graph):\n",
    "    # 加载预训练模型参数\n",
    "    model.set_dict(paddle.load(os.path.join(config.model_path, config.model_name + '.params')))\n",
    "    model.eval()\n",
    "    \n",
    "    # 加载数据集并进行预测\n",
    "    test_ids = load_test(config.test)\n",
    "    pred = model(graph, graph.node_feat[\"feat\"])\n",
    "    pred = paddle.gather(pred, test_ids)\n",
    "    pred = paddle.argmax(F.softmax(pred, axis=1), axis=1).numpy()\n",
    "\n",
    "    # 保存预测结果文件\n",
    "    df = pd.DataFrame({'nid': test_ids, 'label': pred})\n",
    "    df.to_csv(os.path.join(config.result_path, config.model_name + '.csv'), index=False)\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "def main(is_train=True, is_predict=True):\n",
    "    \n",
    "    # 获取配置信息和模型\n",
    "    config, model = get_config_model('ResGAT')\n",
    "\n",
    "    print('train model: ', config.model_name)\n",
    "    \n",
    "\n",
    "    # 定义损失函数，优化器\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "    optimizer = paddle.optimizer.AdamW(parameters=model.parameters(), learning_rate=config.lr)\n",
    "\n",
    "    # 获取训练、测试数据\n",
    "    graph = build_graph(config)\n",
    "    graph.tensor()\n",
    "    train_ids, train_labels, eval_ids, eval_labels = load_train(config.train)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    if is_train:\n",
    "        print('start training...')\n",
    "        for epoch in range(config.epoch):\n",
    "            train_loss, train_acc = train(train_ids, train_labels, model, graph, criterion, optimizer)\n",
    "            eval_loss, eval_acc = evaluate(eval_ids, eval_labels, model, graph, criterion)\n",
    "\n",
    "            if epoch % 20 == 0:\n",
    "                print('epoch: {} train_loss: {:.4f} train_acc: {:.4f} eval_loss: {:.4f} eval_acc: {:.4f}'.format(\n",
    "                        epoch, train_loss, train_acc, eval_loss, eval_acc))\n",
    "\n",
    "            # 每找到一个最好的模型就保存下来\n",
    "            if eval_acc > best_acc:\n",
    "                best_acc = eval_acc\n",
    "                paddle.save(model.state_dict(), os.path.join(config.model_path, config.model_name + '.params'))\n",
    "    \n",
    "    if is_predict:\n",
    "        print('start predicting...')\n",
    "        predict(model, config, graph)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 训练完成之后立即对结果进行预测\n",
    "    main(False, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
